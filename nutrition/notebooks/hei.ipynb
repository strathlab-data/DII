{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4d7182",
   "metadata": {},
   "source": [
    "### Healthy Eating Index (HEI) Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb4ba24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyreadstat\n",
      "  Downloading pyreadstat-1.2.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from pyreadstat) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/vscode/.local/lib/python3.11/site-packages (from pandas>=1.2.0->pyreadstat) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.11/site-packages (from pandas>=1.2.0->pyreadstat) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.11/site-packages (from pandas>=1.2.0->pyreadstat) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vscode/.local/lib/python3.11/site-packages (from pandas>=1.2.0->pyreadstat) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.17.0)\n",
      "Downloading pyreadstat-1.2.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (617 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m617.7/617.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyreadstat\n",
      "Successfully installed pyreadstat-1.2.9\n"
     ]
    }
   ],
   "source": [
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace89894",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DR1IFDCD'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'DR1IFDCD'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df_merged.groupby(\u001b[33m\"\u001b[39m\u001b[33mSEQN\u001b[39m\u001b[33m\"\u001b[39m)[agg_cols].sum().reset_index()\n\u001b[32m     44\u001b[39m fped_p1 = build_fped_person(dr1iff)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m fped_p2 = \u001b[43mbuild_fped_person\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdr2iff\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# 5) FUNCTION TO MERGE AND CALCULATE HEI FOR A GIVEN DAY\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalc_day_hei\u001b[39m(dr_tot, fped_person):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mbuild_fped_person\u001b[39m\u001b[34m(df_food)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_fped_person\u001b[39m(df_food):\n\u001b[32m     38\u001b[39m     df_food = df_food.copy()\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     df_food[\u001b[33m\"\u001b[39m\u001b[33mFOODCODE\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf_food\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDR1IFDCD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     40\u001b[39m     df_merged = df_food.merge(fped, on=\u001b[33m\"\u001b[39m\u001b[33mFOODCODE\u001b[39m\u001b[33m\"\u001b[39m, how=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m     agg_cols = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m fped.columns \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mFOODCODE\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mDESCRIPTION\u001b[39m\u001b[33m\"\u001b[39m)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'DR1IFDCD'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "def download_xpt(url):\n",
    "    \"\"\"Download an NHANES .xpt file and return a pandas DataFrame.\"\"\"\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".xpt\") as tmp:\n",
    "        tmp.write(r.content)\n",
    "        tmp.flush()\n",
    "        return pd.read_sas(tmp.name, format=\"xport\")\n",
    "\n",
    "# 1) DOWNLOAD NHANES DAY 1 DATA (correct URLs)\n",
    "DR1IFF_URL = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/DR1IFF_J.xpt\"\n",
    "DR1TOT_URL = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/DR1TOT_J.xpt\"\n",
    "DR2IFF_URL = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/DR2IFF_J.xpt\"\n",
    "DR2TOT_URL = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/DR2TOT_J.xpt\"\n",
    "DEMO_URL   = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/DEMO_J.xpt\"\n",
    "\n",
    "dr1iff = download_xpt(DR1IFF_URL)   # individual foods\n",
    "dr1tot = download_xpt(DR1TOT_URL)   # nutrient totals\n",
    "demo   = download_xpt(DEMO_URL)     # demographics\n",
    "\n",
    "# 2) LOAD LOCAL FPED CSV (per-person field equivalents)\n",
    "FPED_PATH = \"/workspaces/enterntainment720/nutrition/data/raw/FPED_1718.csv\"\n",
    "fped = pd.read_csv(FPED_PATH)\n",
    "\n",
    "# 3) ENSURE SEQN IS INTEGER\n",
    "for df_ in (dr1iff, dr1tot, demo):\n",
    "    df_[\"SEQN\"] = df_[\"SEQN\"].astype(int)\n",
    "\n",
    "# 4) JOIN FOODS → FPED ON EXACT COLUMN NAMES\n",
    "dr1iff[\"FOODCODE\"] = dr1iff[\"DR1IFDCD\"].astype(int)\n",
    "fped[\"FOODCODE\"]   = fped[\"FOODCODE\"].astype(int)\n",
    "foods_fped = dr1iff.merge(fped, on=\"FOODCODE\", how=\"left\")\n",
    "\n",
    "# 5) AGGREGATE FPED TO PERSON-LEVEL\n",
    "# Exclude FOODCODE + DESCRIPTION\n",
    "agg_cols = [c for c in fped.columns if c not in (\"FOODCODE\",\"DESCRIPTION\")]\n",
    "fped_person = foods_fped.groupby(\"SEQN\")[agg_cols].sum().reset_index()\n",
    "\n",
    "# 6) MERGE PERSON-LEVEL FPED WITH NUTRIENTS + DEMO\n",
    "df = (\n",
    "    dr1tot\n",
    "    .merge(demo, on=\"SEQN\", how=\"left\")\n",
    "    .merge(fped_person, on=\"SEQN\", how=\"left\")\n",
    ")\n",
    "\n",
    "# 7) COMPUTE PER-1 000 KCAL & % ENERGY (use exact FPED names)\n",
    "df[\"DR1TKCAL\"] = df[\"DR1TKCAL\"].replace(0, np.nan)  # calories\n",
    "\n",
    "df[\"total_fruit_1000kcal\"]      = df[\"F_TOTAL (cup eq.)\"]   / df[\"DR1TKCAL\"] * 1000\n",
    "df[\"whole_fruit_1000kcal\"]      = (df[\"F_TOTAL (cup eq.)\"] - df[\"F_JUICE (cup eq.)\"]) / df[\"DR1TKCAL\"] * 1000\n",
    "df[\"total_veg_1000kcal\"]        = df[\"V_TOTAL (cup eq.)\"]   / df[\"DR1TKCAL\"] * 1000\n",
    "df[\"greens_beans_1000kcal\"]     = (df[\"V_DRKGR (cup eq.)\"] + df[\"V_LEGUMES (cup eq.)\"]) / df[\"DR1TKCAL\"] * 1000\n",
    "df[\"whole_grain_1000kcal\"]      = df[\"G_WHOLE (oz. eq.)\"]    / df[\"DR1TKCAL\"] * 1000\n",
    "df[\"dairy_1000kcal\"]            = df[\"D_TOTAL (cup eq.)\"]    / df[\"DR1TKCAL\"] * 1000\n",
    "df[\"total_protein_1000kcal\"]    = df[\"PF_TOTAL (oz. eq.)\"]   / df[\"DR1TKCAL\"] * 1000\n",
    "df[\"sea_plant_protein_1000kcal\"]= (\n",
    "    df[\"PF_SEAFD_HI (oz. eq.)\"] + df[\"PF_SEAFD_LOW (oz. eq.)\"] +\n",
    "    df[\"PF_SOY (oz. eq.)\"] + df[\"PF_NUTSDS (oz. eq.)\"] +\n",
    "    df[\"PF_LEGUMES (oz. eq.)\"]\n",
    ") / df[\"DR1TKCAL\"] * 1000\n",
    "\n",
    "# Fatty acid ratio (PUFA+MUFA)/SFA\n",
    "df[\"fatty_acid_ratio\"] = (df[\"DR1TM181\"] + df[\"DR1TP182\"] + df[\"DR1TP183\"]) / df[\"DR1TSFAT\"]\n",
    "\n",
    "# Moderation: lower is better\n",
    "df[\"refined_grain_1000kcal\"] = df[\"G_REFINED (oz. eq.)\"]   / df[\"DR1TKCAL\"] * 1000\n",
    "df[\"sodium_1000kcal\"]        = df[\"DR1TSODI\"]             / df[\"DR1TKCAL\"] * 1000\n",
    "df[\"added_sugars_pct\"]       = df[\"ADD_SUGARS (tsp. eq.)\"] * 4 / df[\"DR1TKCAL\"] * 100\n",
    "df[\"sat_fat_pct\"]            = df[\"DR1TSFAT\"] * 9         / df[\"DR1TKCAL\"] * 100\n",
    "\n",
    "# 8) SCORING HELPERS\n",
    "def capped_score(val, lo, hi, max_score):\n",
    "    return np.clip((val - lo)/(hi - lo)*max_score, 0, max_score)\n",
    "\n",
    "def reverse_capped(val, lo, hi, max_score):\n",
    "    return np.clip((hi - val)/(hi - lo)*max_score, 0, max_score)\n",
    "\n",
    "# 9) APPLY HEI-2015 CUTPOINTS\n",
    "df[\"hei_total_fruit\"]       = capped_score(df[\"total_fruit_1000kcal\"],    0, 0.8,  5)\n",
    "df[\"hei_whole_fruit\"]       = capped_score(df[\"whole_fruit_1000kcal\"],    0, 0.4,  5)\n",
    "df[\"hei_total_veg\"]         = capped_score(df[\"total_veg_1000kcal\"],      0, 1.1,  5)\n",
    "df[\"hei_greens_beans\"]      = capped_score(df[\"greens_beans_1000kcal\"],   0, 0.2,  5)\n",
    "df[\"hei_whole_grains\"]      = capped_score(df[\"whole_grain_1000kcal\"],    0, 1.5, 10)\n",
    "df[\"hei_dairy\"]             = capped_score(df[\"dairy_1000kcal\"],          0, 1.3, 10)\n",
    "df[\"hei_total_protein\"]     = capped_score(df[\"total_protein_1000kcal\"],  0, 2.5,  5)\n",
    "df[\"hei_sea_plant_protein\"] = capped_score(df[\"sea_plant_protein_1000kcal\"],0, 0.8,  5)\n",
    "df[\"hei_fatty_acids\"]       = capped_score(df[\"fatty_acid_ratio\"],        1.2,2.5, 10)\n",
    "df[\"hei_refined_grains\"]    = reverse_capped(df[\"refined_grain_1000kcal\"],1.8,4.3, 10)\n",
    "df[\"hei_sodium\"]            = reverse_capped(df[\"sodium_1000kcal\"],       1.1,2.0, 10)\n",
    "df[\"hei_added_sugars\"]      = reverse_capped(df[\"added_sugars_pct\"],      6.5,26.0,10)\n",
    "df[\"hei_sat_fat\"]           = reverse_capped(df[\"sat_fat_pct\"],           8.0,16.0,10)\n",
    "\n",
    "# 10) TOTAL HEI SCORE\n",
    "hei_cols = [c for c in df.columns if c.startswith(\"hei_\")]\n",
    "df[\"HEI2015_TOTAL_SCORE\"] = df[hei_cols].sum(axis=1)\n",
    "\n",
    "# 11) EXPORT HEI SCORES TO CSV\n",
    "output_path = \"/workspaces/enterntainment720/nutrition/data/output/hei_scores.csv\"\n",
    "df[[\"SEQN\", \"HEI2015_TOTAL_SCORE\"] + hei_cols].to_csv(output_path, index=False)\n",
    "print(f\"HEI scores written to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "284dc726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usual‐intake HEI saved to /workspaces/enterntainment720/nutrition/data/output/hei_usual_intake.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "def download_xpt(url):\n",
    "    \"\"\"Download an NHANES .xpt file and return a pandas DataFrame.\"\"\"\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".xpt\") as tmp:\n",
    "        tmp.write(r.content); tmp.flush()\n",
    "        return pd.read_sas(tmp.name, format=\"xport\")\n",
    "\n",
    "# 1) URLs for NHANES 2017–2018 Day 1 & Day 2\n",
    "DR1IFF_URL = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/DR1IFF_J.xpt\"\n",
    "DR1TOT_URL = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/DR1TOT_J.xpt\"\n",
    "DR2IFF_URL = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/DR2IFF_J.xpt\"\n",
    "DR2TOT_URL = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/DR2TOT_J.xpt\"\n",
    "DEMO_URL   = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/DEMO_J.xpt\"\n",
    "\n",
    "# 2) Download NHANES files\n",
    "dr1iff = download_xpt(DR1IFF_URL)\n",
    "dr1tot = download_xpt(DR1TOT_URL)\n",
    "dr2iff = download_xpt(DR2IFF_URL)\n",
    "dr2tot = download_xpt(DR2TOT_URL)\n",
    "demo   = download_xpt(DEMO_URL)\n",
    "\n",
    "# 3) Load your FPED per-food CSV\n",
    "FPED_PATH = \"/workspaces/enterntainment720/nutrition/data/raw/FPED_1718.csv\"\n",
    "fped      = pd.read_csv(FPED_PATH)\n",
    "\n",
    "# 4) Ensure SEQN is integer everywhere\n",
    "for df_ in (dr1iff, dr1tot, dr2iff, dr2tot, demo):\n",
    "    df_[\"SEQN\"] = df_[\"SEQN\"].astype(int)\n",
    "\n",
    "# 5) Helper to build person-level FPED totals from individual foods\n",
    "def build_fped_person(ind_df, code_col):\n",
    "    df_food = ind_df.copy()\n",
    "    df_food[\"FOODCODE\"] = df_food[code_col].astype(int)\n",
    "    merged = df_food.merge(fped, on=\"FOODCODE\", how=\"left\")\n",
    "    agg_cols = [c for c in fped.columns if c not in (\"FOODCODE\", \"DESCRIPTION\")]\n",
    "    return merged.groupby(\"SEQN\")[agg_cols].sum().reset_index()\n",
    "\n",
    "fped_p1 = build_fped_person(dr1iff, \"DR1IFDCD\")\n",
    "fped_p2 = build_fped_person(dr2iff, \"DR2IFDCD\")\n",
    "\n",
    "# 6) Function to calculate HEI for a single day, using the given prefix (DR1 or DR2)\n",
    "def calc_day_hei(dr_tot, fped_person, prefix):\n",
    "    # merge\n",
    "    df = dr_tot.merge(demo, on=\"SEQN\", how=\"left\").merge(fped_person, on=\"SEQN\", how=\"left\")\n",
    "    kcal_col = f\"{prefix}TKCAL\"\n",
    "    df[kcal_col] = df[kcal_col].replace(0, np.nan)\n",
    "\n",
    "    # per-1000kcal\n",
    "    df[\"total_fruit\"]       = df[\"F_TOTAL (cup eq.)\"]   / df[kcal_col] * 1000\n",
    "    df[\"whole_fruit\"]       = (df[\"F_TOTAL (cup eq.)\"] - df[\"F_JUICE (cup eq.)\"]) / df[kcal_col] * 1000\n",
    "    df[\"total_veg\"]         = df[\"V_TOTAL (cup eq.)\"]   / df[kcal_col] * 1000\n",
    "    df[\"greens_beans\"]      = (\n",
    "        df[\"V_DRKGR (cup eq.)\"] + df[\"V_LEGUMES (cup eq.)\"]\n",
    "    ) / df[kcal_col] * 1000\n",
    "    df[\"whole_grain\"]       = df[\"G_WHOLE (oz. eq.)\"]    / df[kcal_col] * 1000\n",
    "    df[\"dairy\"]             = df[\"D_TOTAL (cup eq.)\"]    / df[kcal_col] * 1000\n",
    "    df[\"total_protein\"]     = df[\"PF_TOTAL (oz. eq.)\"]   / df[kcal_col] * 1000\n",
    "    df[\"sea_plant_protein\"] = (\n",
    "        df[\"PF_SEAFD_HI (oz. eq.)\"] + df[\"PF_SEAFD_LOW (oz. eq.)\"] +\n",
    "        df[\"PF_SOY (oz. eq.)\"] + df[\"PF_NUTSDS (oz. eq.)\"] +\n",
    "        df[\"PF_LEGUMES (oz. eq.)\"]\n",
    "    ) / df[kcal_col] * 1000\n",
    "\n",
    "    # fatty acids ratio\n",
    "    mufacol = f\"{prefix}TM181\"\n",
    "    pufacol = f\"{prefix}TP182\"\n",
    "    pufbcol = f\"{prefix}TP183\"\n",
    "    sfatcol = f\"{prefix}TSFAT\"\n",
    "    df[\"fatty_acid_ratio\"] = (df[mufacol] + df[pufacol] + df[pufbcol]) / df[sfatcol]\n",
    "\n",
    "    # moderation (reverse)\n",
    "    df[\"refined_grain\"]  = df[\"G_REFINED (oz. eq.)\"]    / df[kcal_col] * 1000\n",
    "    df[\"sodium\"]         = df[f\"{prefix}TSODI\"]        / df[kcal_col] * 1000\n",
    "    df[\"added_sugars\"]   = df[\"ADD_SUGARS (tsp. eq.)\"]  * 4  / df[kcal_col] * 100\n",
    "    df[\"sat_fat\"]        = df[sfatcol]                 * 9  / df[kcal_col] * 100\n",
    "\n",
    "    # scoring helpers\n",
    "    def cap(v, lo, hi, mx): return np.clip((v-lo)/(hi-lo)*mx, 0, mx)\n",
    "    def rcap(v, lo, hi, mx): return np.clip((hi-v)/(hi-lo)*mx, 0, mx)\n",
    "\n",
    "    # apply\n",
    "    s = {}\n",
    "    s[1] = cap(df[\"total_fruit\"],    0,   0.8,   5)\n",
    "    s[2] = cap(df[\"whole_fruit\"],    0,   0.4,   5)\n",
    "    s[3] = cap(df[\"total_veg\"],      0,   1.1,   5)\n",
    "    s[4] = cap(df[\"greens_beans\"],   0,   0.2,   5)\n",
    "    s[5] = cap(df[\"whole_grain\"],    0,   1.5,  10)\n",
    "    s[6] = cap(df[\"dairy\"],          0,   1.3,  10)\n",
    "    s[7] = cap(df[\"total_protein\"],  0,   2.5,   5)\n",
    "    s[8] = cap(df[\"sea_plant_protein\"],0, 0.8,   5)\n",
    "    s[9] = cap(df[\"fatty_acid_ratio\"],1.2,2.5,  10)\n",
    "    s[10]= rcap(df[\"refined_grain\"], 1.8, 4.3,  10)\n",
    "    s[11]= rcap(df[\"sodium\"],        1.1, 2.0,  10)\n",
    "    s[12]= rcap(df[\"added_sugars\"],  6.5,26.0,  10)\n",
    "    s[13]= rcap(df[\"sat_fat\"],       8.0,16.0,  10)\n",
    "\n",
    "    for i in range(1,14):\n",
    "        df[f\"s{i}\"] = s[i]\n",
    "    df[\"HEI\"] = df[[f\"s{i}\" for i in range(1,14)]].sum(axis=1)\n",
    "    return df[[\"SEQN\",\"HEI\"] + [f\"s{i}\" for i in range(1,14)]]\n",
    "\n",
    "# 7) CALCULATE\n",
    "day1 = calc_day_hei(dr1tot, fped_p1, prefix=\"DR1\")\n",
    "day2 = calc_day_hei(dr2tot, fped_p2, prefix=\"DR2\")\n",
    "\n",
    "# 8) AVERAGE\n",
    "hei = day1.merge(day2, on=\"SEQN\", suffixes=(\"_day1\",\"_day2\"))\n",
    "hei[\"HEI_usual\"] = hei[[\"HEI_day1\",\"HEI_day2\"]].mean(axis=1)\n",
    "\n",
    "# 9) SAVE\n",
    "out = \"/workspaces/enterntainment720/nutrition/data/output/hei_usual_intake.csv\"\n",
    "hei.to_csv(out, index=False)\n",
    "print(\"Usual‐intake HEI saved to\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6d54c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
